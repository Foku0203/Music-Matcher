import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D, MaxPooling2D
from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Activation, Add
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.utils import class_weight
import numpy as np
import matplotlib.pyplot as plt
import os

# ==========================================
# 1. ‚öôÔ∏è CONFIGURATION (‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤)
# ==========================================
IMG_SIZE = 48    # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô FER2013
BATCH_SIZE = 64  # ‡πÄ‡∏û‡∏¥‡πà‡∏° Batch size ‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ö‡∏≤
EPOCHS = 100     # ‡πÄ‡∏ó‡∏£‡∏ô‡∏¢‡∏≤‡∏ß‡πÜ ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡∏ô‡∏≤‡∏ô‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ
DATA_DIR = 'FER2013DATA' # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# ==========================================
# 2. üìÇ DATA GENERATORS (‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
# ==========================================
# Mini-Xception ‡∏ä‡∏≠‡∏ö‡∏†‡∏≤‡∏û Grayscale (channel=1)
train_datagen = ImageDataGenerator(
    featurewise_center=False,
    featurewise_std_normalization=False,
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=.1,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator() # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á preprocess ‡∏≠‡∏∞‡πÑ‡∏£‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Validation

print("\nüöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û...")
train_generator = train_datagen.flow_from_directory(
    os.path.join(DATA_DIR, 'train'),
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='grayscale',  # ‚ö†Ô∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True
)

validation_generator = val_datagen.flow_from_directory(
    os.path.join(DATA_DIR, 'test'),
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='grayscale',  # ‚ö†Ô∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Class Weights
print("\n‚öñÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Class Weights...")
class_weights_val = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
train_class_weights = dict(enumerate(class_weights_val))
print(f"Weights: {train_class_weights}")

# ==========================================
# 3. üß† MODEL ARCHITECTURE (Mini-Xception Fixed)
# ==========================================
def build_mini_xception(input_shape=(48, 48, 1), num_classes=7, l2_reg=0.01):
    regularization = l2(l2_reg)

    # Input Image
    img_input = Input(input_shape)
    
    # Block 1: Conv ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    # Blocks 2-5: Residual Blocks (‡πÉ‡∏ä‡πâ Depthwise/Pointwise Regularizer ‡πÅ‡∏ó‡∏ô Kernel)
    for filters in [16, 32, 64, 128]:
        residual = Conv2D(filters, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)
        residual = BatchNormalization()(residual)
        
        # ‚ö†Ô∏è FIX: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô kernel_regularizer ‡πÄ‡∏õ‡πá‡∏ô pointwise_regularizer
        x = SeparableConv2D(filters, (3, 3), padding='same', 
                            pointwise_regularizer=regularization, 
                            depthwise_regularizer=regularization,
                            use_bias=False)(x)
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        
        x = SeparableConv2D(filters, (3, 3), padding='same', 
                            pointwise_regularizer=regularization, 
                            depthwise_regularizer=regularization,
                            use_bias=False)(x)
        x = BatchNormalization()(x)
        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)
        
        x = Add()([x, residual]) # Skip Connection
        
    # Output Block
    x = Conv2D(num_classes, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)
    x = GlobalAveragePooling2D()(x)
    output = Activation('softmax', name='predictions')(x)

    model = Model(img_input, output)
    return model

model = build_mini_xception()
model.summary()

# ==========================================
# 4. üèãÔ∏è TRAINING
# ==========================================
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
checkpoint = ModelCheckpoint(
    'mini_xception_best.keras', 
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10, # ‡∏£‡∏≠‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏•‡∏á‡∏ä‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

print("\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô Mini-Xception...")
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=EPOCHS, 
    validation_data=validation_generator,
    validation_steps=len(validation_generator),
    callbacks=[checkpoint, early_stopping, reduce_lr],
    class_weight=train_class_weights 
)

print("\n‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

# ==========================================
# 5. üìä PLOT RESULTS
# ==========================================
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(acc, label='Train Accuracy')
plt.plot(val_acc, label='Val Accuracy')
plt.title('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Train Loss')
plt.plot(val_loss, label='Val Loss')
plt.title('Loss')
plt.legend()

plt.show()